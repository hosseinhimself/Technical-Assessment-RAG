{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQQ29p+3FIzjbziyM6DOsi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hosseinhimself/Technical-Assessment-RAG/blob/main/Untitled19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PAaE0BBKgEOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba43d14-7ba0-458f-fd6d-a04d3a892339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.2/853.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q fastapi uvicorn\n",
        "!pip install -q llama-index\n",
        "!pip install -q llama-index-embeddings-huggingface\n",
        "\n",
        "!pip install -q faiss-cpu\n",
        "!pip install -q llama-index-vector-stores-faiss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from llama_index.core import Settings, SimpleDirectoryReader, VectorStoreIndex\n",
        "\n",
        "\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "pvJm1k-OgNMc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentProcessor:\n",
        "    def __init__(self, directory):\n",
        "        self.directory = directory\n",
        "        self.documents = self.load_documents()\n",
        "\n",
        "    def load_documents(self):\n",
        "        documents = SimpleDirectoryReader(self.directory).load_data()\n",
        "        return self.refine_documents(documents)\n",
        "\n",
        "    def refine_documents(self, documents):\n",
        "        refined_docs = []\n",
        "        for doc in documents:\n",
        "            if \"Member-only story\" in doc.text or \"The Data Entrepreneurs\" in doc.text or \" min read\" in doc.text:\n",
        "                continue\n",
        "            refined_docs.append(doc)\n",
        "        return refined_docs\n",
        "\n",
        "    def get_texts(self):\n",
        "        return [doc.text for doc in self.documents]\n",
        "\n",
        "    def add_document(self, document):\n",
        "        refined_doc = self.refine_documents([document])\n",
        "        if refined_doc:\n",
        "            self.documents.extend(refined_doc)\n",
        "            return refined_doc[0]\n",
        "        return None"
      ],
      "metadata": {
        "id": "X_ZCNor_gUQU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingModel:\n",
        "    def __init__(self, model_name):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "    def get_embeddings(self, texts):\n",
        "        inputs = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "53fGeEe1gkSW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaissIndex:\n",
        "    def __init__(self, dimension):\n",
        "        self.index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "    def add_embeddings(self, embeddings):\n",
        "        self.index.add(embeddings)\n",
        "\n",
        "    def save(self, index_file, documents_file, embeddings_file, documents):\n",
        "        faiss.write_index(self.index, index_file)\n",
        "        with open(documents_file, \"wb\") as f:\n",
        "            pickle.dump(documents, f)\n",
        "        np.save(embeddings_file, embeddings)\n",
        "\n",
        "    def load(self, index_file, documents_file, embeddings_file):\n",
        "        self.index = faiss.read_index(index_file)\n",
        "        with open(documents_file, \"rb\") as f:\n",
        "            documents = pickle.load(f)\n",
        "        embeddings = np.load(embeddings_file)\n",
        "        return documents, embeddings\n",
        "\n",
        "    def add_document(self, document, embedding):\n",
        "        self.add_embeddings(np.array([embedding]))"
      ],
      "metadata": {
        "id": "JLCdCqc7gp9d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QueryEngine:\n",
        "    def __init__(self, retriever, embedding_model):\n",
        "        self.retriever = retriever\n",
        "        self.embedding_model = embedding_model\n",
        "\n",
        "    def query(self, query_text):\n",
        "        query_embedding = self.embedding_model.get_embeddings([query_text])[0]\n",
        "        retrieved_documents = self.retriever.retrieve(query_embedding)\n",
        "        context = \"Context:\\n\"\n",
        "        for doc in retrieved_documents:\n",
        "            context += doc.text + \"\\n\\n\"\n",
        "        return context\n",
        "\n",
        "    def add_document(self, document_text):\n",
        "        # Create a new Document object\n",
        "        new_document = BaseModel(text=document_text)\n",
        "        # Add the document to the DocumentProcessor\n",
        "        refined_document = self.retriever.documents.append(new_document)\n",
        "        if refined_document:\n",
        "            # Generate the embedding for the new document\n",
        "            new_embedding = self.embedding_model.get_embeddings([document_text])[0]\n",
        "            # Add the document and its embedding to the FAISS index\n",
        "            self.retriever.index.add_document(refined_document, new_embedding)"
      ],
      "metadata": {
        "id": "4YoSWbPtgtSV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaissRetriever:\n",
        "    def __init__(self, index, documents, top_k):\n",
        "        self.index = index\n",
        "        self.documents = documents\n",
        "        self.top_k = top_k\n",
        "\n",
        "    def retrieve(self, query_embedding):\n",
        "        distances, indices = self.index.search(np.array([query_embedding]), self.top_k)\n",
        "        return [self.documents[idx] for idx in indices[0]]"
      ],
      "metadata": {
        "id": "m82vtXLM_Mza"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Settings\n",
        "    Settings.llm = None\n",
        "    Settings.chunk_size = 256\n",
        "    Settings.chunk_overlap = 25\n",
        "\n",
        "    # Initialize components\n",
        "    directory = \"articles\"\n",
        "    model_name = \"thenlper/gte-large\"\n",
        "    index_file = \"faiss_index.index\"\n",
        "    documents_file = \"documents.pkl\"\n",
        "    embeddings_file = \"embeddings.npy\"\n",
        "    top_k = 3\n",
        "\n",
        "    '''# Process documents\n",
        "    doc_processor = DocumentProcessor(directory)\n",
        "    texts = doc_processor.get_texts()\n",
        "    print(f\"Number of documents after refinement: {len(texts)}\")\n",
        "\n",
        "    # Generate embeddings\n",
        "    embedding_model = EmbeddingModel(model_name)\n",
        "    embeddings = embedding_model.get_embeddings(texts)\n",
        "\n",
        "    # Initialize FAISS index and add embeddings\n",
        "    faiss_index = FaissIndex(dimension=embeddings.shape[1])\n",
        "    faiss_index.add_embeddings(embeddings)\n",
        "\n",
        "    # Save index, documents, and embeddings\n",
        "    faiss_index.save(index_file, documents_file, embeddings_file, doc_processor.documents)\n",
        "    '''\n",
        "    # Load index, documents, and embeddings\n",
        "    documents, embedding_matrix = faiss_index.load(index_file, documents_file, embeddings_file)\n",
        "\n",
        "    # Initialize retriever\n",
        "    retriever = FaissRetriever(faiss_index.index, documents, top_k)\n",
        "\n",
        "    # Initialize query engine\n",
        "    query_engine = QueryEngine(retriever, embedding_model)\n",
        "\n",
        "    # Example query\n",
        "    query_text = \"Power Laws Break STAT 101\"\n",
        "    context = query_engine.query(query_text)\n",
        "    print(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgptrYOJg1qV",
        "outputId": "8e89d885-f28f-49d2-9a9e-36b38eea7a3e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM is explicitly disabled. Using MockLLM.\n",
            "Context:\n",
            "One of the biggest problems in using STAT 101 techniques to analyze Power\n",
            "Laws (i.e. data from Extremistan) is quantities like mean, standard deviation,\n",
            "variance, correlation, etc. all have little practical significance.\n",
            "This all stems from a single core issue — insufficient data.\n",
            "In statistics, we learn about the Law of Large Numbers, which says that if we\n",
            "take N random samples, the sample mean will approach the true mean as N\n",
            "→ ∞. This is true for ANY distribution (with finite mean): Gaussian, Power\n",
            "Law, Uniform, you name it.\n",
            "However, it turns out that this asymptotic behavior happens more slowly for\n",
            "some distributions than others (e.g. slower for Power Laws than Gaussians).\n",
            "And, in practice, where we (necessarily) have finite datasets, this can cause\n",
            "problems. Here, I highlight 3 such problems.\n",
            "Problem 1: The Mean is Meaningless (as well as many other\n",
            "metrics)\n",
            "Whenever we want to compare two sets of values (e.g. sales in April vs. May,\n",
            "traffic accidents in LA vs. NYC, patient outcomes in the control vs. treatment\n",
            "group), we often compute a mean. This gives us an intuitive way to compress\n",
            "several values into a single representative number.\n",
            "This works incredibly well for data that follow a nice Gaussian distribution\n",
            "because one can accurately estimate the mean in small sample sizes\n",
            "(N=~10). However, this approach breaks down when working with data\n",
            "following a Power Law distribution.\n",
            "We can see this by comparing Gaussian and Power Law sample means as\n",
            "sample size increases, as shown in the plots below for N=100, N=1,000, and\n",
            "\n",
            "favorite statistical tools become useless when applied to a particular class of\n",
            "data — Power Laws.\n",
            "In this article, I will provide a beginner-friendly guide to Power Laws and\n",
            "describe 3 major problems with using traditional statistical methods to\n",
            "analyze them.\n",
            "Table of Contents\n",
            "1. Background — The Gaussian Distribution, Pareto’s 80 – 20 Rule, Power Laws,\n",
            "and the difference between weight and wealth.\n",
            "2. 3 Problems with STAT 101 — you need (a lot) more data.\n",
            "3. Fat Tails — avoiding controversy and quantifying the gap between Gauss and\n",
            "Pareto.\n",
            "\n",
            "Example Power Law distributions with various α values. Note: α = 1.16 approximately implies the 80 – 20 rule.\n",
            "Image by author.\n",
            "As we can see in the plots above, Power Laws are qualitatively very different\n",
            "from the Gaussian distribution. This forms a sort of dichotomy between\n",
            "Gaussian-like and Pareto-like distributions. Put another way, Gaussian and\n",
            "Power Law distributions provide conceptual anchors to qualitatively\n",
            "categorize things in the real world.\n",
            "Mediocristan Vs Extremistan\n",
            "Author Nassim Nicholas Taleb describes this dichotomy between Gaussian-\n",
            "like and Pareto-like things via two categories he calls “Mediocristan” and\n",
            "“Extremistan.”\n",
            "Mediocristan is the land of Gaussian-like things. A fundamental property of\n",
            "its citizens is no single observation will significantly impact the aggregate\n",
            "statistics [3]. For example, suppose you weigh every tourist at the Colosseum\n",
            "during your trip to Rome and compute the average weight. If you added the\n",
            "heaviest Italian on Earth, this average would be essentially unchanged\n",
            "(+0.5%).\n",
            "On the other side of this conceptual landscape is Extremistan, where we see\n",
            "an opposite statistical property. Namely, in Extremistan, a single\n",
            "observation can (and often will) drive the aggregate statistics. Consider the\n",
            "same tourists at the Colosseum, but instead of measuring their weight, you\n",
            "ask each their net worth and compute the average. Unlike before, this\n",
            "average would change dramatically (+2500%) if we added the world’s richest\n",
            "Italian, Giovanni Ferrero (the chocolate + hazelnut family), to the sample.\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}